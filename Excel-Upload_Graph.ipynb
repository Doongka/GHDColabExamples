{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualising Data.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doongka/GHDColabExamples/blob/master/Excel-Upload_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8chuCFBZsZKx",
        "colab_type": "text"
      },
      "source": [
        "## Why use Python instead of Excel for data analysis?\n",
        "The water sector is a data rich environment and the amount of data being collected is steadily increasing.  This provides us with new opportunities for exploiting this data in our day to day work.\n",
        "\n",
        "Even though Excel is a powerful tool, it does have some limitations.  Most notably is the poor performance with a spreadsheet full of formula and the row/column limitation. When our data is too big for a spreadsheet or we require lots of calculations we can create a coded solution using a language like Python.\n",
        "\n",
        " So what makes Python so attractive for data analysis?\n",
        "\n",
        "1.   Readable and easily maintainable\n",
        "2.   Very easy to learn and use.\n",
        "3.   Open source (FREE!) and feature rich with lots of libraries available\n",
        "4.   Cross platform support. i.e. code written on Mac can run on Windows (mostly)\n",
        "5.   Most importantly, it's better suited for big data applications (Not the best but the easiest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emFym08P7uPv",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization Example\n",
        "The goal of this notebook is to provide a quick overview of some useful Python tools used for cleaning, analysing and visualizing data.\n",
        "\n",
        "The notebook has  been created using Google Colab, a free cloud-based notebook environment that allows you to write and execute Python code without needing to set up your own local Python environment.\n",
        "\n",
        "Anyone can use this notebook and I'll send a link out on an email.  It's sitting in my online code repository located here:-\n",
        "\n",
        "https://colab.research.google.com/github/Doongka/GHDColabExamples/blob/master/Visualising_Data.ipynb\n",
        "\n",
        "This notebook will allow you to run the code in segments as you go.  When you get to a code block, you can execute (run) the code by pressing CTRL-ENTER.  \n",
        "\n",
        "Try it on the code block below:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbb119Xo9g2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign \"Hello World!\" to a new variable \"greeting\"\n",
        "greeting = \"Hello World!\"\n",
        "\n",
        "# run the \"print\" function with \"greeting\" as an argument. i.e. Print to screen whatever is stored in \"greeting\"\n",
        "print(greeting)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgJeubrs_kb4",
        "colab_type": "text"
      },
      "source": [
        "If successful you will see the words \"Hello World!\" output below the code.\n",
        "\n",
        "Something important to note is that a # symbol at the start of a line causes Python to ignore that particular line. This is useful to provide a description of your code like I've done above or to stop lines of code from running with debugging. A quick way to \"comment\" and \"uncomment\" your code is to press CTRL-/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgPfO6FWnMEe",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the workspace\n",
        "Google Colab has many useful Python packages preinstalled such so there shouldn't be any need to install them yourself.  Packages are basically collections of useful functions.  If case you do need something that is not installed, you can run a \"pip\" installation as per below.  \n",
        "\n",
        "You can see that I've \"commented\" the bit of code that installs the package \"\".  Uncomment this line and run the code block.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tOQpc6XK1xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We place a ! in front of the command to indicate that we want this to run in a console.\n",
        "# !pip install altair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFsenpopExeC",
        "colab_type": "text"
      },
      "source": [
        "## Uploading your data to Colab\n",
        "The first step in any data analysis is to prepare the data.  As we are running this in Google Colab, we need to upload any datasets.  There are several ways to do this but for this example I've used the most intuitive. \n",
        "\n",
        "I've downloaded some temperature data from BOM to try out. You can download the test data here:-\n",
        "\n",
        "https://raw.githubusercontent.com/Doongka/GHDColabExamples/master/dataset/brisbanetemp.csv\n",
        "\n",
        "After running the cell below, you will see a \"Choose Files\" button that will allow you to select the files you wish to upload.  This example has been designed to handle a single CSV file so point to where you saved the \"brisbanetemp.csv\" file on your local machine\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wITgvJetPcws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeqC4zZP53R7",
        "colab_type": "text"
      },
      "source": [
        "Running the next cell will give you an overview of the files you have just uploaded.  This is a handy test to make sure it uploaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42WBIjwKd46C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnGYpvHuFWy-",
        "colab_type": "text"
      },
      "source": [
        "## Wrangling your data\n",
        "\n",
        "Python has many pre-built packages that help with any extract, transform and load (ETL) operations required to get the data ready.  The standard library contains lots of really good methods but sometimes we want something even better.\n",
        "\n",
        "Pandas is a popular library that provides many useful methods for data manipulation. We will be using the \"Dataframe\" functionality which will allow us to import data from a CSV file and perform several data wrangling and cleansing tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8FV3yb-FlLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#These commands allow us to load the libraries in to our current notebook\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QwiIKEbGice",
        "colab_type": "text"
      },
      "source": [
        "## Loading your data\n",
        "Before we can do anything with our data, we first need to load it.  Pandas has some great methods to read files and load them into a useful format. \n",
        "\n",
        "In the code block below, we are loading a CSV file and tranforming it in the form of a Dataframe object.  A Dataframe is effectively Pandas's answer to storing data in a tabular format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz0QoS3MQ5_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the csv and load the contents into memory as a dataframe\n",
        "data = pd.read_csv('brisbanetemp.csv')\n",
        "\n",
        "# the head() method allows us to view the first 5 entries in the dataframe\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ZGjoeGtPg7",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning up your data\n",
        "You can see from the table above that row 0 has data that is unable to be read.  \"NaN\" means \"Not a Number\" and in this case was caused by empty cells in the first row of the data.  Let's remove this row entry using the following command. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwIsdDIYtOTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop the first row from the dataframe and assign to a new Dataframe called \"cleansed_data\"\n",
        "cleansed_data = data.drop(data.index[0])\n",
        "\n",
        "# Let's have a look to see if it worked\n",
        "cleansed_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9AaPHwy_Zw9",
        "colab_type": "text"
      },
      "source": [
        "We don't need the columns \"Site Number\" or \"Site Name\" so we'll drop these too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfz8u9QGuQxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop the columns 'site number' and 'site name'\n",
        "cleansed_data = cleansed_data.drop(['site number', 'site name'], axis=1)\n",
        "\n",
        "# check to see what we're left with\n",
        "cleansed_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUQy3Ck3_tPD",
        "colab_type": "text"
      },
      "source": [
        "Looking good but we should check the rest of the data.  Running the \"info\" method gives us information on the type of data stored in each column and also the number of non-null (not empty or NaN) entries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCAqvjoAu1jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleansed_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN4GnPLn_9qL",
        "colab_type": "text"
      },
      "source": [
        "We can see that the number of non-null entries for each column is not equal.  This means there are null entries sitting in our table.  We can search for them by doing the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2tlPffdvzNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the null values in the first column\n",
        "missing_data = cleansed_data['maximum temperature (degC)'].isna()\n",
        "\n",
        "# find the null values in the second column.  We are using a logical OR (|) to get a combined list of null entries\n",
        "missing_data = missing_data | cleansed_data['minimum temperature (degC)'].isna()\n",
        "\n",
        "# Count the number of rows that have null entries\n",
        "missing_data.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_AaKvLDANiU",
        "colab_type": "text"
      },
      "source": [
        "We have 63 rows that contain at least one null value.  Let's take a look:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9VBOp-1w0E6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show only the rows that contain the null values.  Note the format.  The input number represents the rows we want, the second is the columns we want.  A colon (:)\n",
        "# means we want to show all columns\n",
        "cleansed_data.loc[missing_data,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X9oz0VTBK5G",
        "colab_type": "text"
      },
      "source": [
        "We have several options at out disposal here to handle the null entries, we can:\n",
        "\n",
        "  \n",
        "\n",
        "*   delete the rows but that's generally not a good idea for time series data \n",
        "*   back or forward filling the entry using the values around it\n",
        "*   interpolate between values\n",
        "\n",
        "Let's interpolate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byLUfjffxqHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can remove all of the rows that have NaNs.  Probably not a good idea for a time series plot but necessary if the data can't be imputed\n",
        "# final_data = cleansed_data.dropna(how='any')\n",
        "\n",
        "# We can back fill the data based on the data either side\n",
        "# final_data = cleansed_data.fillna(method='bfill')\n",
        "# Or forward fill\n",
        "# final_data = cleansed_data.fillna(method='ffill')\n",
        "\n",
        "# We can interpolate \n",
        "final_data = cleansed_data.interpolate(method='linear')\n",
        "final_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrb_IjhGBw8U",
        "colab_type": "text"
      },
      "source": [
        "We can see that we now have the equal numbers of entries for each column.  The last thing we need to do is to make sure the date is in a usable format for the graph.  We can do this by using the \"to_datetime\" method in Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHrUT96QyrQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fix the data column so it is in a usable format\n",
        "final_data['date'] = pd.to_datetime(final_data['date'],format=\"%d/%m/%Y\")\n",
        "\n",
        "# Rename the columns so they're easier to read\n",
        "final_data = final_data.rename(columns={\"maximum temperature (degC)\": \"max_temp\", \"minimum temperature (degC)\": \"min_temp\"})\n",
        "\n",
        "# take a final look at the data\n",
        "final_data.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETMQt2sapFYN",
        "colab_type": "text"
      },
      "source": [
        "We can also get a summary of key statistics by using the .describe() command\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR8SYeB2o6iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a the summay stats from the dataset\n",
        "final_data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yABVKYm3F1J6",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing your Data\n",
        "\n",
        "\n",
        "Altair is a great data visualization library that is preinstalled in Colab.  It is a statistical visualization language with lots of plot types and statistical functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHjVrHELDVb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load up the Altair package to give us access to advanced visualization methods\n",
        "import altair as alt\n",
        "\n",
        "# Altair has a default 5000 entry limit, this can be turned off but we'll keep it on for this example\n",
        "start_date = '2008-01-01'\n",
        "end_date =  '2018-12-31'\n",
        "\n",
        "# We need to create a mask to pull out the data we want.  This basically tells us the row indexes that sit between the two dates\n",
        "mask = (final_data['date'] > start_date) & (final_data['date'] <= end_date)\n",
        "\n",
        "# We'll create a new dataframe to store our plot data.  The .loc[mask] method returns the entries based on the indexes we obtained above\n",
        "plot_data = final_data.loc[mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ackdeInM3sbY",
        "colab_type": "text"
      },
      "source": [
        "Altair is a bit involved to produce a plot and takes a while to get used to but it produces beautiful plots.  The example below is an interactive scatterplot that allows us to zoom in and out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoX_TRHBSYFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The code below produces an interactive scatterplot that lets us zoom in and out\n",
        "alt.Chart(plot_data, height=500, width=1000).mark_circle().encode(\n",
        "    alt.X('date:T',\n",
        "          scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    alt.Y('max_temp:Q',\n",
        "          scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    tooltip=['date', 'max_temp', 'min_temp'],\n",
        "    color=alt.Color('max_temp:Q', sort='descending', scale=alt.Scale(scheme=alt.SchemeParams(name='redyellowblue')))\n",
        ").interactive()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7ALGbA3-6e",
        "colab_type": "text"
      },
      "source": [
        "Here is the same plot but with the ability to select data in the graph and produce the histogram below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKOGdULXO6IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a more complex example.  This plot allows us to select a region of data and produce a histogram\n",
        "brush = alt.selection(type='interval')\n",
        "\n",
        "points = alt.Chart(plot_data, height=500, width=1000).mark_point().encode(\n",
        "    alt.X('date:T',\n",
        "          scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    alt.Y('max_temp:Q',\n",
        "          scale=alt.Scale(zero=False)\n",
        "    ),\n",
        "    color=alt.condition(brush, 'max_temp:Q', alt.value('lightgray'),sort='descending', scale=alt.Scale(scheme=alt.SchemeParams(name='redyellowblue')) ),\n",
        ").add_selection(\n",
        "    brush\n",
        ")\n",
        "\n",
        "bars = alt.Chart(plot_data, height=250, width=1000).mark_bar().encode(\n",
        "    alt.Y('count()',scale=alt.Scale(domain=[0, 60])),\n",
        "    alt.X('max_temp:Q', scale=alt.Scale(domain=[0, 40])),\n",
        "    color='max_temp:Q'\n",
        ").transform_filter(\n",
        "    brush\n",
        ")\n",
        "\n",
        "points & bars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieLwrEmM4JmL",
        "colab_type": "text"
      },
      "source": [
        "The BOM dataset didn't have any categorical data but a built in Altair dataset does.  This lets us build complex plots like this:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8ywnudATkPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import altair as alt\n",
        "from vega_datasets import data\n",
        "\n",
        "source = data.seattle_weather()\n",
        "\n",
        "scale = alt.Scale(domain=['sun', 'fog', 'drizzle', 'rain', 'snow'],\n",
        "                  range=['#e7ba52', '#a7a7a7', '#aec7e8', '#1f77b4', '#9467bd'])\n",
        "color = alt.Color('weather:N', scale=scale)\n",
        "\n",
        "# We create two selections:\n",
        "# - a brush that is active on the top panel\n",
        "# - a multi-click that is active on the bottom panel\n",
        "brush = alt.selection_interval(encodings=['x'])\n",
        "click = alt.selection_multi(encodings=['color'])\n",
        "\n",
        "# Top panel is scatter plot of temperature vs time\n",
        "points = alt.Chart(height=750, width=1000).mark_point().encode(\n",
        "    alt.X('monthdate(date):T', title='Date'),\n",
        "    alt.Y('temp_max:Q',\n",
        "        title='Maximum Daily Temperature (C)',\n",
        "        scale=alt.Scale(domain=[-5, 40])\n",
        "    ),\n",
        "    color=alt.condition(brush, color, alt.value('lightgray')),\n",
        "    size=alt.Size('precipitation:Q', scale=alt.Scale(range=[5, 200]))\n",
        ").properties(\n",
        "    width=1000,\n",
        "    height=500\n",
        ").add_selection(\n",
        "    brush\n",
        ").transform_filter(\n",
        "    click\n",
        ")\n",
        "\n",
        "# Bottom panel is a bar chart of weather type\n",
        "bars = alt.Chart().mark_bar().encode(\n",
        "    x='count()',\n",
        "    y='weather:N',\n",
        "    color=alt.condition(click, color, alt.value('lightgray')),\n",
        ").transform_filter(\n",
        "    brush\n",
        ").properties(\n",
        "    width=1000,\n",
        ").add_selection(\n",
        "    click\n",
        ")\n",
        "\n",
        "alt.vconcat(\n",
        "    points,\n",
        "    bars,\n",
        "    data=source,\n",
        "    title=\"Seattle Weather: 2012-2015\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcJifmNgPuEO",
        "colab_type": "text"
      },
      "source": [
        "# Mapping\n",
        "\n",
        "You can even use python to produce maps.  The \"folium\" packages allows you to access OpenStreetMap, an open source collection of maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaa9yGoNOlv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import folium\n",
        "folium.Map(\n",
        "        width='75%', \n",
        "        height='75%',\n",
        "        location=[-27.4698, 153.0251],\n",
        "        zoom_start=15,\n",
        "        tiles='Stamen Terrain')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}